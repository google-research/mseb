{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1Ela_CcRtohP4-dm0cZQusKhTSpCTK97y",
          "timestamp": 1764897944728
        }
      ],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before starting:\n",
        "\n",
        "*  Go to Runtime menu and change runtime type to T4 GPU\n",
        "*  The first pip install cell will require restart of runtime after running.\n",
        "*  You must have HF_TOKEN colab secret set to download models."
      ],
      "metadata": {
        "id": "D4IfyxTUqVur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xSdHELzGbJ0a"
      },
      "outputs": [],
      "source": [
        "# You will be asked to restart the session after this install.\n",
        "!pip install git+https://github.com/google-research/mseb/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scann\n",
        "!pip install whisper"
      ],
      "metadata": {
        "id": "iF6nEqdNh_tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mseb\n",
        "from mseb.datasets import parquet as parquet_datasets\n",
        "try:\n",
        "  # scann import throws because __init__ tries to enable unused tf ops.\n",
        "  from mseb.encoders import hf_llm_encoder\n",
        "except:\n",
        "  # but the deps are actually loaded, will succeed second try.\n",
        "  from mseb.encoders import hf_llm_encoder\n",
        "\n",
        "from pprint import pprint\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "GUhShaVIbNMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set huggingface read token.\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['HF_TOKEN'] = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "IC4SlbF-lVQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "assert torch.cuda.device_count() > 0"
      ],
      "metadata": {
        "id": "Q-9E5gQlp66o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify some encoders\n",
        "from mseb.encoders import raw_encoder\n",
        "from mseb.encoders import prompt_registry\n",
        "\n",
        "from absl import flags\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS([\"colab\",\n",
        "       \"--dataset_basepath=https://storage.googleapis.com/mseb_asru_tutorial\",\n",
        "       \"--task_cache_basepath=/tmp/cache\"])\n",
        "assert FLAGS.dataset_basepath\n",
        "\n",
        "spectrogram_encoder = raw_encoder.RawEncoder(\n",
        "  frame_length=25,\n",
        "  frame_step=10,\n",
        "  transform_fn=raw_encoder.spectrogram_transform,\n",
        "  pooling=\"mean\",\n",
        ")\n",
        "\n",
        "gemma_encoder = hf_llm_encoder.HFLLMWithTitleAndContextEncoder(\n",
        "  model_path=\"google/gemma-3n-E2B-it\",\n",
        "  prompt=prompt_registry.get_prompt_metadata(\"intent_classification\").load(),\n",
        ")"
      ],
      "metadata": {
        "id": "P_4p-YWT0Sd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_registry.get_prompt_metadata(\"intent_classification\").load()\n",
        "pprint(prompt.GetPromptTemplate())"
      ],
      "metadata": {
        "id": "4AL2jI566c4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downsampled tasks\n",
        "\n",
        "For demonstration purposes, we have sampled small subsets of the evaluation datasets to use in colab and made them available on gcs. We'll override the datasets of a few tasks here to point to the pre-sampled demo data."
      ],
      "metadata": {
        "id": "qjYB8D_JyWlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passage retrieval (SimpleVoiceQuestions).\n",
        "from mseb.tasks.retrievals.passage_in_lang import svq as passage_retrieval_svq\n",
        "\n",
        "class ParquetDataset(parquet_datasets.ParquetDataset):\n",
        "  def get_sound(self, record):\n",
        "    if 'audio' not in record:\n",
        "      record = self._data.loc[self._data['utt_id'] == record['utt_id']].iloc[0].to_dict()\n",
        "    return super().get_sound(record)\n",
        "\n",
        "class SVQEnUsPassageInLangRetrieval(passage_retrieval_svq.SVQEnUsPassageInLangRetrieval):\n",
        "  def _get_dataset(self):\n",
        "    return ParquetDataset(\n",
        "        dataset_name=\"svq\",\n",
        "        task_name=\"passage_retrieval_in_lang\",\n",
        "        filename=\"SimpleVoiceQuestionsDataset_passage_retrieval_in_lang_locale_en_us.parquet\",\n",
        "        sample_n=2)\n",
        "\n",
        "pprint(SVQEnUsPassageInLangRetrieval.metadata)"
      ],
      "metadata": {
        "id": "xLTvnPoM-s0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sound.\n",
        "task = SVQEnUsPassageInLangRetrieval()\n",
        "sound = next(iter(task.sounds()))\n",
        "pprint(sound)\n",
        "Audio(sound.waveform, rate=sound.context.sample_rate)"
      ],
      "metadata": {
        "id": "qKahVLQqABSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation examples.\n",
        "example = next(iter(task.examples('passage_retrieval_in_lang')))\n",
        "pprint(example)"
      ],
      "metadata": {
        "id": "4FUiTpROE5dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intent classification (SpeechMassive).\n",
        "from mseb.tasks.classifications.intent import speech_massive\n",
        "\n",
        "# Override with the demo data.\n",
        "class SpeechMassiveFrFrIntentClassification(speech_massive.SpeechMassiveFrFrIntentClassification):\n",
        "  def _get_dataset(self):\n",
        "    return parquet_datasets.ParquetDataset(\n",
        "        dataset_name=\"speech_massive\",\n",
        "        task_name=\"SpeechMassiveFrFrIntentClassification\",\n",
        "        filename=\"SpeechMassiveDataset_task_language_fr-FR.parquet\",\n",
        "        sample_n=2)\n",
        "\n",
        "pprint(SpeechMassiveFrFrIntentClassification.metadata)"
      ],
      "metadata": {
        "id": "LVvpfJwlsJMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect sounds used by the task which will be passed through the encoder.\n",
        "task = SpeechMassiveFrFrIntentClassification()\n",
        "sound = next(iter(task.sounds()))\n",
        "pprint(sound)\n",
        "Audio(sound.waveform, rate=sound.context.sample_rate)"
      ],
      "metadata": {
        "id": "V_Zv80cI3yMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The examples evaluated by the class.\n",
        "example = next(iter(task.examples('intent')))\n",
        "pprint(example)"
      ],
      "metadata": {
        "id": "HVBbV8ur5Gpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the encoder do with the audio?\n",
        "# Here our example is gemma3n prompted to produce the class labels of this task.\n",
        "encoded = gemma_encoder.encode([sound])\n",
        "pprint(encoded)"
      ],
      "metadata": {
        "id": "1dNM8ZaA5_I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running tasks.\n",
        "\n",
        "The mechanism for running the encoder across as task is help in the Runner.\n",
        "For this colab, the runner will be the DirectRunner that simply iterates over the data in python and executes the encoder locally. A BeamRunner is supplied\n",
        "for running in distributed settings, and the Runner interface can be implemented\n",
        "by an end-user to customize how to distribute work in their local environement."
      ],
      "metadata": {
        "id": "IQdJQEVwzIZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a task. This is how the run_task script runs a benchmark.\n",
        "\n",
        "from mseb.runner import DirectRunner\n",
        "from mseb.leaderboard import run_benchmark\n",
        "\n",
        "def run_task(encoder_name, encoder, task):\n",
        "  runner = DirectRunner(encoder=gemma_encoder, batch_size=1)\n",
        "\n",
        "  # Setup runs global task pre-processing, for instance, running encoder over\n",
        "  # corpous for retrieval and building index. Not all tasks will have a setup\n",
        "  # step.\n",
        "  task.setup(runner=runner)\n",
        "\n",
        "  # Run benchmark uses the runner to encode all the task sounds and then calls\n",
        "  # the task evaluator.\n",
        "  return run_benchmark(encoder_name=encoder, runner=runner, task=task)\n",
        "\n",
        "result = run_task(\n",
        "    encoder_name=\"gemma_intent_classification\",\n",
        "    encoder=gemma_encoder,\n",
        "    task=SpeechMassiveFrFrIntentClassification())\n",
        "pprint(result)\n"
      ],
      "metadata": {
        "id": "krBexX_V-rjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
