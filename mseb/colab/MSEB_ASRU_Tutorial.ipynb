{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "11r2XGkloTabLmU4kCzVdUdm2zqPbAUYH",
          "timestamp": 1764974064666
        }
      ],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before starting:\n",
        "\n",
        "*  Go to Runtime menu and change runtime type to T4 GPU\n",
        "*  The first pip install cell will require restart of runtime after running.\n",
        "*  You must have HF_TOKEN colab secret set to download models: Use the key icon in the left side toolbar."
      ],
      "metadata": {
        "id": "D4IfyxTUqVur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xSdHELzGbJ0a"
      },
      "outputs": [],
      "source": [
        "# You will be asked to restart the session after this install.\n",
        "%%capture\n",
        "!pip install git+https://github.com/google-research/mseb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install scann\n",
        "!pip install whisper"
      ],
      "metadata": {
        "id": "iF6nEqdNh_tH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mseb\n",
        "from mseb.datasets import parquet as parquet_datasets\n",
        "try:\n",
        "  # scann import throws because __init__ tries to enable unused tf ops.\n",
        "  from mseb.encoders import hf_llm_encoder\n",
        "except:\n",
        "  # but the deps are actually loaded, will succeed second try.\n",
        "  from mseb.encoders import hf_llm_encoder\n",
        "\n",
        "from pprint import pprint\n",
        "from IPython.display import Audio\n",
        "import json\n",
        "\n",
        "from absl import flags\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS([\"colab\",\n",
        "       \"--dataset_basepath=https://storage.googleapis.com/mseb_asru_tutorial\",\n",
        "       \"--task_cache_basepath=/tmp/cache\"])\n",
        "assert FLAGS.dataset_basepath"
      ],
      "metadata": {
        "id": "GUhShaVIbNMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set huggingface read token.\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['HF_TOKEN'] = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "IC4SlbF-lVQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "assert torch.cuda.device_count() > 0"
      ],
      "metadata": {
        "id": "Q-9E5gQlp66o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks\n",
        "\n",
        "MSEB has six classes of task:\n",
        "*  classification\n",
        "*  clustering\n",
        "*  reasoning\n",
        "*  reranking\n",
        "*  retrieval\n",
        "*  segmentation\n",
        "\n",
        "For demonstration purposes, we have sampled small subsets of the evaluation datasets to use in colab and made them available on gcs. We'll override the datasets of a few tasks here to point to the pre-sampled demo data.\n",
        "\n",
        "We will look at two instances of tasks for this demo:\n",
        "*  **Intent Classification** (SpeechMassive)\n",
        "*  **Passage Retrieval** (SimpleVoiceQuestions)"
      ],
      "metadata": {
        "id": "qjYB8D_JyWlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intent classification (SpeechMassive).\n",
        "from mseb.tasks.classifications.intent import speech_massive\n",
        "\n",
        "# Override with the demo data.\n",
        "class SpeechMassiveFrFrIntentClassification(speech_massive.SpeechMassiveFrFrIntentClassification):\n",
        "  def _get_dataset(self):\n",
        "    return parquet_datasets.ParquetDataset(\n",
        "        dataset_name=\"speech_massive\",\n",
        "        task_name=\"SpeechMassiveFrFrIntentClassification\",\n",
        "        filename=\"SpeechMassiveDataset_task_language_fr-FR.parquet\",\n",
        "        sample_n=2)\n",
        "\n",
        "pprint(SpeechMassiveFrFrIntentClassification.metadata)"
      ],
      "metadata": {
        "id": "LVvpfJwlsJMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect sounds used by the task which will be passed through the encoder.\n",
        "task = SpeechMassiveFrFrIntentClassification()\n",
        "sound = next(task.sounds())\n",
        "pprint(sound)\n",
        "Audio(sound.waveform, rate=sound.context.sample_rate)"
      ],
      "metadata": {
        "id": "V_Zv80cI3yMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation examples.\n",
        "example = next(iter(task.examples('passage_retrieval_in_lang')))\n",
        "pprint(example)"
      ],
      "metadata": {
        "id": "4FUiTpROE5dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passage retrieval (SimpleVoiceQuestions).\n",
        "from mseb.tasks.retrievals.passage_in_lang import svq as passage_retrieval_svq\n",
        "from mseb.datasets.parquet import ParquetDataset\n",
        "from mseb import types as mseb_types\n",
        "\n",
        "class SVQEnUsPassageInLangRetrieval(passage_retrieval_svq.SVQEnUsPassageInLangRetrieval):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self._ds = None\n",
        "    self._get_dataset()\n",
        "\n",
        "  def _get_dataset(self):\n",
        "    if not self._ds:\n",
        "      self._ds = ParquetDataset(\n",
        "          dataset_name=\"svq\",\n",
        "          task_name=\"passage_retrieval_in_lang\",\n",
        "          filename=\"SimpleVoiceQuestionsDataset_passage_retrieval_in_lang_locale_en_us.parquet\",\n",
        "          sample_n=2)\n",
        "    return self._ds\n",
        "\n",
        "  # Get the corpus from pre-computed top passage sets.\n",
        "  def documents(self):\n",
        "    ds = self._get_dataset().get_task_data(\"passage_retrieval_in_lang\")\n",
        "    top_passages = ds[\"top100_passages_gemini_embedding_whisper_transcript\"]\n",
        "    for x in top_passages:\n",
        "      for x in [json.loads(line) for line in x.splitlines() if line.strip()]:\n",
        "        yield mseb_types.Text(\n",
        "            text=x[\"text\"],\n",
        "            context=mseb_types.TextContextParams(title=\"no title\", id=x[\"id\"]))\n",
        "\n",
        "pprint(SVQEnUsPassageInLangRetrieval.metadata)"
      ],
      "metadata": {
        "id": "xLTvnPoM-s0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sound.\n",
        "task = SVQEnUsPassageInLangRetrieval()\n",
        "sound = next(task.sounds())\n",
        "pprint(sound)\n",
        "Audio(sound.waveform, rate=sound.context.sample_rate)"
      ],
      "metadata": {
        "id": "qKahVLQqABSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The examples evaluated by the class.\n",
        "example = next(task.examples('passage_retrieval_in_lang'))\n",
        "pprint(example)"
      ],
      "metadata": {
        "id": "HVBbV8ur5Gpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passage corpus.\n",
        "corpus = task.documents()\n",
        "pprint(next(corpus))"
      ],
      "metadata": {
        "id": "VAc8MXSMh8Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoders"
      ],
      "metadata": {
        "id": "ELQ9yt5nn2DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder imports and definitions.\n",
        "from mseb.encoders import raw_encoder\n",
        "from mseb.encoders import gecko_encoder\n",
        "from mseb.encoders import prompt_registry\n",
        "\n",
        "spectrogram_encoder = raw_encoder.RawEncoder(\n",
        "  frame_length=25,\n",
        "  frame_step=10,\n",
        "  transform_fn=raw_encoder.spectrogram_transform,\n",
        "  pooling=\"mean\",\n",
        ")\n",
        "\n",
        "gemma_intent_classification = hf_llm_encoder.HFLLMWithTitleAndContextEncoder(\n",
        "  model_path=\"google/gemma-3n-E2B-it\",\n",
        "  prompt=prompt_registry.get_prompt_metadata(\"intent_classification\").load(),\n",
        ")"
      ],
      "metadata": {
        "id": "P_4p-YWT0Sd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt is part of the encoding process for a particular use case.\n",
        "prompt = prompt_registry.get_prompt_metadata(\"intent_classification\").load()\n",
        "pprint(prompt.GetPromptTemplate())"
      ],
      "metadata": {
        "id": "4AL2jI566c4R",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run encoder: gemma3n prompted to produce the class labels of this task.\n",
        "gemma_intent_classification.setup()\n",
        "encoded = gemma_intent_classification.encode([sound])\n",
        "pprint(encoded)"
      ],
      "metadata": {
        "id": "1dNM8ZaA5_I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running task/encoder benchmarks.\n",
        "\n",
        "The mechanism for running the encoder across as task is help in the Runner.\n",
        "For this colab, the runner will be the DirectRunner that simply iterates over the data in python and executes the encoder locally. A BeamRunner is supplied\n",
        "for running in distributed settings, and the Runner interface can be implemented\n",
        "by an end-user to customize how to distribute work in their local environement."
      ],
      "metadata": {
        "id": "IQdJQEVwzIZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a task. This is how the run_task script runs a benchmark.\n",
        "\n",
        "from mseb.runner import DirectRunner\n",
        "from mseb.leaderboard import run_benchmark\n",
        "\n",
        "def run_task(encoder_name, encoder, task):\n",
        "  runner = DirectRunner(encoder=encoder, batch_size=1)\n",
        "\n",
        "  # Setup runs global task pre-processing, for instance, running encoder over\n",
        "  # corpous for retrieval and building index. Not all tasks will have a setup\n",
        "  # step.\n",
        "  task.setup(runner=runner)\n",
        "\n",
        "  # Run benchmark uses the runner to encode all the task sounds and then calls\n",
        "  # the task evaluator.\n",
        "  return run_benchmark(encoder_name=encoder, runner=runner, task=task)\n",
        "\n",
        "result = run_task(\n",
        "    encoder_name=\"gemma_intent_classification\",\n",
        "    encoder=gemma_intent_classification,\n",
        "    task=SpeechMassiveFrFrIntentClassification())\n",
        "pprint(result)\n"
      ],
      "metadata": {
        "id": "krBexX_V-rjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
